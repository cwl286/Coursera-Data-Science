---
title: "Capstone Project Milestone Report"
author: "Chris Gomes"
date: "August 29, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load libraries}
library(ggplot2)
library(stringi)
```

## Abstract

We download the data sets that will be used to construct a prediction app. We clean the data and then perform some exploratory data analysis. We begin to think about how to build the algorithm for 
our app.

## Data Processing

### Download the Data Sets

The data is stored in a zip file which may be downloaded [here](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip).

```{r download, cache=TRUE}
src_file <- "https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip"
dest_file <- "capstone-data.zip"

# Download and extract the files
download.file(src_file, dest_file)
unzip(dest_file)
```

Let's see which files we've downloaded.
```{r inspect the extracted files, cache=TRUE}
unzip(dest_file, list = TRUE )
```

We consider only the Enlish language files.
```{r inspect the English language files, cache=TRUE}
list.files("final")
list.files("final/en_US")
```

### Save the English Language Files

We save the text data to three files: `blogs`, `news`, and `twitter`.
```{r Create the files blogs, news, and twitter, cache=TRUE}
blogs <- readLines("final/en_US/en_US.blogs.txt", encoding = "UTF-8", skipNul=TRUE)
news <- readLines("final/en_US/en_US.news.txt", encoding = "UTF-8", skipNul=TRUE)
twitter <- readLines("final/en_US/en_US.twitter.txt", encoding = "UTF-8", skipNul=TRUE)

# save the data to an .RData files
save(blogs, file="blogs.RData")
save(news, file="news.RData")
save(twitter, file="twitter.RData")
```

## Some Basic Statistics

First, we look at properties of the files themselves.

```{r file properties, cache=TRUE}
# Check the files sizes
blogs_size <- file.info("final/en_US/en_US.blogs.txt")$size / 1024.0 / 1024.0
news_size <- file.info("final/en_US/en_US.news.txt")$size / 1024.0 / 1024.0
twitter_size <- file.info("final/en_US/en_US.twitter.txt")$size / 1024.0 / 1024.0

# Use stringi to get data about numbers of lines and word counts for each file
stri_stats_general(blogs)
stri_stats_general(news)
stri_stats_general(twitter)

# word counts
blog_words <- stri_count_words(blogs)
news_words <- stri_count_words(news)
twitter_words <- stri_count_words(twitter)
```

We look at summaries and word distributions for each file.

```{r summaries and plots}
summary(blog_words)
qplot(blog_words, binwidth=1, xlim=c(1, 100))

summary(news_words)
qplot(news_words, binwidth=1, xlim=c(1, 100))

summary(twitter_words)
qplot(twitter_words, binwidth=1, xlim=c(1, 100))
```



